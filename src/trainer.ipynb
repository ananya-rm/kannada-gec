{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd81b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43f68b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:48:26,402 :: root         : INFO     Configured the logging successfully\n"
     ]
    }
   ],
   "source": [
    "from bert.bert_model import BERT_model\n",
    "import logging\n",
    "from util import logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9534a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(size=None):\n",
    "    #df = pd.read_csv('data/train.tsv', delimiter='\\t', header=None)\n",
    "    df = pd.read_csv(\"C:/Users/anany/Desktop/fyp/data/kn/kannada-dataset/input2.txt\", delimiter=', ', header=None)\n",
    "\n",
    "    if size:\n",
    "        df = df[:size]\n",
    "    logging.info('Trainig data:{}'.format(df.shape))\n",
    "    logging.info('Class distribution:\\n{}'.format(df[1].value_counts()))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba95e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_sent_length(tokenized_df):\n",
    "    max_len = 0\n",
    "    for i in tokenized_df.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c22def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_metrics(act, pred):\n",
    "    logging.info('Confusion Matrix:\\n' + str(confusion_matrix(act, pred)))\n",
    "    logging.info('Report:\\n' + str(classification_report(act, pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b5d2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_classifier(bert_feature_array, target_labels, TEST_RATIO=0.1):\n",
    "    # Split train and test\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(bert_feature_array, target_labels,\n",
    "    test_size=TEST_RATIO)\n",
    "\n",
    "    # Train the model\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    logging.info('Training complete')\n",
    "\n",
    "    # Get the test results\n",
    "    pred_labels = classifier.predict(test_features)\n",
    "    # logging.info('Pred:{}'.format(pred_labels))\n",
    "    # Print the evaluation results\n",
    "    print_test_metrics(test_labels, pred_labels)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b14b3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer():\n",
    "    # Load the TSV training data\n",
    "    df = get_data()\n",
    "\n",
    "    # Load the tokenizer and BERT models\n",
    "    bert = BERT_model()\n",
    "    bert.load_BERT(small=True)\n",
    "\n",
    "    # Tokenize the sentences in the training data\n",
    "    tokenized_df = df[0].apply(lambda sent: bert.tokenize_sentence(sent))\n",
    "    MAX_LEN = get_max_sent_length(tokenized_df)\n",
    "    logging.info('Maximum sentence length:{}'.format(MAX_LEN))\n",
    "\n",
    "    # Provide the tokenized sentences and get the BERT embeddings back\n",
    "    bert_hidden_states = bert.convert_tokenized_sent_to_bert_emb(tokenized_df, MAX_LEN, batch_size=500)\n",
    "    # TODO Save the features and target lables\n",
    "\n",
    "    # Slice the hidden states of shape (number of training examples, max number of tokens=MAX_LEN, number of hidden units in BERT=768)\n",
    "    # And take only the CLS output of the BERT\n",
    "    bert_feature_array = bert_hidden_states[:,0,:].numpy()\n",
    "\n",
    "    logging.info('Bert features shape:{}'.format(bert_feature_array.shape))\n",
    "    # The target labels\n",
    "    target_labels = df[1]\n",
    "\n",
    "    # Train a classifier\n",
    "    classifier= sentence_classifier(bert_feature_array, target_labels)\n",
    "    \n",
    "    return classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4b48979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:49:59,915 :: root         : INFO     Trainig data:(45798, 2)\n",
      "2024-03-15 23:49:59,923 :: root         : INFO     Class distribution:\n",
      "1    40392\n",
      "0     5406\n",
      "Name: 1, dtype: int64\n",
      "2024-03-15 23:50:06,986 :: root         : INFO     BERT has been loaded successfully\n",
      "2024-03-15 23:50:12,839 :: root         : INFO     Maximum sentence length:18\n",
      "2024-03-15 23:50:13,324 :: root         : INFO     Padded array shape:(45798, 18)\n",
      "2024-03-15 23:50:13,329 :: root         : INFO     Attention mask shape:(45798, 18)\n",
      "2024-03-15 23:50:13,331 :: root         : INFO     Going to get BERT embeddings for 45798 records\n",
      "2024-03-15 23:50:13,331 :: root         : INFO     Running batch-wise. Original shape:(45798, 18)\n",
      "2024-03-15 23:53:02,315 :: root         : INFO     Time taken:168 seconds\n",
      "2024-03-15 23:55:43,435 :: root         : INFO     Time taken:161 seconds\n",
      "2024-03-15 23:55:43,457 :: root         : INFO     Accumulated emb size:torch.Size([1000, 18, 768])\n",
      "2024-03-15 23:58:24,979 :: root         : INFO     Time taken:161 seconds\n",
      "2024-03-15 23:58:24,998 :: root         : INFO     Accumulated emb size:torch.Size([1500, 18, 768])\n",
      "2024-03-16 00:01:06,424 :: root         : INFO     Time taken:161 seconds\n",
      "2024-03-16 00:01:06,445 :: root         : INFO     Accumulated emb size:torch.Size([2000, 18, 768])\n",
      "2024-03-16 00:03:47,306 :: root         : INFO     Time taken:160 seconds\n",
      "2024-03-16 00:03:47,336 :: root         : INFO     Accumulated emb size:torch.Size([2500, 18, 768])\n",
      "2024-03-16 00:06:29,468 :: root         : INFO     Time taken:162 seconds\n",
      "2024-03-16 00:06:29,509 :: root         : INFO     Accumulated emb size:torch.Size([3000, 18, 768])\n",
      "2024-03-16 00:09:11,272 :: root         : INFO     Time taken:161 seconds\n",
      "2024-03-16 00:09:11,307 :: root         : INFO     Accumulated emb size:torch.Size([3500, 18, 768])\n",
      "2024-03-16 00:11:53,318 :: root         : INFO     Time taken:162 seconds\n",
      "2024-03-16 00:11:53,367 :: root         : INFO     Accumulated emb size:torch.Size([4000, 18, 768])\n",
      "2024-03-16 00:14:35,586 :: root         : INFO     Time taken:162 seconds\n",
      "2024-03-16 00:14:35,652 :: root         : INFO     Accumulated emb size:torch.Size([4500, 18, 768])\n",
      "2024-03-16 00:17:16,242 :: root         : INFO     Time taken:160 seconds\n",
      "2024-03-16 00:17:16,325 :: root         : INFO     Accumulated emb size:torch.Size([5000, 18, 768])\n",
      "2024-03-16 00:19:58,384 :: root         : INFO     Time taken:162 seconds\n",
      "2024-03-16 00:19:58,468 :: root         : INFO     Accumulated emb size:torch.Size([5500, 18, 768])\n",
      "2024-03-16 00:22:40,344 :: root         : INFO     Time taken:161 seconds\n",
      "2024-03-16 00:22:40,432 :: root         : INFO     Accumulated emb size:torch.Size([6000, 18, 768])\n",
      "2024-03-16 00:25:21,683 :: root         : INFO     Time taken:161 seconds\n",
      "2024-03-16 00:25:21,765 :: root         : INFO     Accumulated emb size:torch.Size([6500, 18, 768])\n",
      "2024-03-16 00:28:06,748 :: root         : INFO     Time taken:164 seconds\n",
      "2024-03-16 00:28:06,860 :: root         : INFO     Accumulated emb size:torch.Size([7000, 18, 768])\n",
      "2024-03-16 00:30:52,877 :: root         : INFO     Time taken:166 seconds\n",
      "2024-03-16 00:30:53,000 :: root         : INFO     Accumulated emb size:torch.Size([7500, 18, 768])\n",
      "2024-03-16 00:33:39,916 :: root         : INFO     Time taken:166 seconds\n",
      "2024-03-16 00:33:40,051 :: root         : INFO     Accumulated emb size:torch.Size([8000, 18, 768])\n",
      "2024-03-16 00:36:25,117 :: root         : INFO     Time taken:165 seconds\n",
      "2024-03-16 00:36:25,244 :: root         : INFO     Accumulated emb size:torch.Size([8500, 18, 768])\n",
      "2024-03-16 00:39:11,106 :: root         : INFO     Time taken:165 seconds\n",
      "2024-03-16 00:39:11,258 :: root         : INFO     Accumulated emb size:torch.Size([9000, 18, 768])\n",
      "2024-03-16 00:41:55,514 :: root         : INFO     Time taken:164 seconds\n",
      "2024-03-16 00:41:55,679 :: root         : INFO     Accumulated emb size:torch.Size([9500, 18, 768])\n",
      "2024-03-16 00:44:39,373 :: root         : INFO     Time taken:163 seconds\n",
      "2024-03-16 00:44:39,538 :: root         : INFO     Accumulated emb size:torch.Size([10000, 18, 768])\n",
      "2024-03-16 00:47:22,861 :: root         : INFO     Time taken:163 seconds\n",
      "2024-03-16 00:47:23,044 :: root         : INFO     Accumulated emb size:torch.Size([10500, 18, 768])\n",
      "2024-03-16 00:50:07,175 :: root         : INFO     Time taken:164 seconds\n",
      "2024-03-16 00:50:07,383 :: root         : INFO     Accumulated emb size:torch.Size([11000, 18, 768])\n",
      "2024-03-16 00:52:53,398 :: root         : INFO     Time taken:166 seconds\n",
      "2024-03-16 00:52:53,612 :: root         : INFO     Accumulated emb size:torch.Size([11500, 18, 768])\n",
      "2024-03-16 05:48:45,834 :: root         : INFO     Time taken:17752 seconds\n",
      "2024-03-16 05:48:46,043 :: root         : INFO     Accumulated emb size:torch.Size([12000, 18, 768])\n",
      "2024-03-16 05:51:23,640 :: root         : INFO     Time taken:157 seconds\n",
      "2024-03-16 05:51:23,793 :: root         : INFO     Accumulated emb size:torch.Size([12500, 18, 768])\n",
      "2024-03-16 05:54:08,442 :: root         : INFO     Time taken:164 seconds\n",
      "2024-03-16 05:54:08,657 :: root         : INFO     Accumulated emb size:torch.Size([13000, 18, 768])\n",
      "2024-03-16 05:56:49,671 :: root         : INFO     Time taken:161 seconds\n",
      "2024-03-16 05:56:49,845 :: root         : INFO     Accumulated emb size:torch.Size([13500, 18, 768])\n",
      "2024-03-16 05:59:35,130 :: root         : INFO     Time taken:165 seconds\n",
      "2024-03-16 05:59:35,346 :: root         : INFO     Accumulated emb size:torch.Size([14000, 18, 768])\n",
      "2024-03-16 06:02:17,577 :: root         : INFO     Time taken:162 seconds\n",
      "2024-03-16 06:02:17,758 :: root         : INFO     Accumulated emb size:torch.Size([14500, 18, 768])\n",
      "2024-03-16 06:04:58,327 :: root         : INFO     Time taken:160 seconds\n",
      "2024-03-16 06:04:58,504 :: root         : INFO     Accumulated emb size:torch.Size([15000, 18, 768])\n",
      "2024-03-16 06:07:38,994 :: root         : INFO     Time taken:160 seconds\n",
      "2024-03-16 06:07:39,183 :: root         : INFO     Accumulated emb size:torch.Size([15500, 18, 768])\n",
      "2024-03-16 06:10:18,694 :: root         : INFO     Time taken:159 seconds\n",
      "2024-03-16 06:10:18,867 :: root         : INFO     Accumulated emb size:torch.Size([16000, 18, 768])\n",
      "2024-03-16 06:12:56,212 :: root         : INFO     Time taken:157 seconds\n",
      "2024-03-16 06:12:56,444 :: root         : INFO     Accumulated emb size:torch.Size([16500, 18, 768])\n",
      "2024-03-16 06:15:33,126 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 06:15:33,322 :: root         : INFO     Accumulated emb size:torch.Size([17000, 18, 768])\n",
      "2024-03-16 06:18:16,175 :: root         : INFO     Time taken:162 seconds\n",
      "2024-03-16 06:18:16,436 :: root         : INFO     Accumulated emb size:torch.Size([17500, 18, 768])\n",
      "2024-03-16 06:20:56,714 :: root         : INFO     Time taken:160 seconds\n",
      "2024-03-16 06:20:56,990 :: root         : INFO     Accumulated emb size:torch.Size([18000, 18, 768])\n",
      "2024-03-16 06:23:33,351 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 06:23:33,578 :: root         : INFO     Accumulated emb size:torch.Size([18500, 18, 768])\n",
      "2024-03-16 06:26:13,367 :: root         : INFO     Time taken:159 seconds\n",
      "2024-03-16 06:26:13,680 :: root         : INFO     Accumulated emb size:torch.Size([19000, 18, 768])\n",
      "2024-03-16 06:28:50,582 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 06:28:50,859 :: root         : INFO     Accumulated emb size:torch.Size([19500, 18, 768])\n",
      "2024-03-16 06:50:06,165 :: root         : INFO     Time taken:1275 seconds\n",
      "2024-03-16 06:50:06,616 :: root         : INFO     Accumulated emb size:torch.Size([20000, 18, 768])\n",
      "2024-03-16 06:52:43,402 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 06:52:43,675 :: root         : INFO     Accumulated emb size:torch.Size([20500, 18, 768])\n",
      "2024-03-16 06:55:21,644 :: root         : INFO     Time taken:157 seconds\n",
      "2024-03-16 06:55:21,883 :: root         : INFO     Accumulated emb size:torch.Size([21000, 18, 768])\n",
      "2024-03-16 06:57:58,114 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 06:57:58,388 :: root         : INFO     Accumulated emb size:torch.Size([21500, 18, 768])\n",
      "2024-03-16 07:00:35,692 :: root         : INFO     Time taken:157 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 07:00:35,934 :: root         : INFO     Accumulated emb size:torch.Size([22000, 18, 768])\n",
      "2024-03-16 07:03:12,688 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 07:03:12,922 :: root         : INFO     Accumulated emb size:torch.Size([22500, 18, 768])\n",
      "2024-03-16 07:05:49,566 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 07:05:49,832 :: root         : INFO     Accumulated emb size:torch.Size([23000, 18, 768])\n",
      "2024-03-16 07:08:26,163 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 07:08:26,472 :: root         : INFO     Accumulated emb size:torch.Size([23500, 18, 768])\n",
      "2024-03-16 07:11:03,104 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 07:11:03,371 :: root         : INFO     Accumulated emb size:torch.Size([24000, 18, 768])\n",
      "2024-03-16 07:13:45,914 :: root         : INFO     Time taken:162 seconds\n",
      "2024-03-16 07:13:46,305 :: root         : INFO     Accumulated emb size:torch.Size([24500, 18, 768])\n",
      "2024-03-16 07:16:31,006 :: root         : INFO     Time taken:164 seconds\n",
      "2024-03-16 07:16:31,290 :: root         : INFO     Accumulated emb size:torch.Size([25000, 18, 768])\n",
      "2024-03-16 07:19:16,968 :: root         : INFO     Time taken:165 seconds\n",
      "2024-03-16 07:19:17,377 :: root         : INFO     Accumulated emb size:torch.Size([25500, 18, 768])\n",
      "2024-03-16 07:22:04,351 :: root         : INFO     Time taken:166 seconds\n",
      "2024-03-16 07:22:04,755 :: root         : INFO     Accumulated emb size:torch.Size([26000, 18, 768])\n",
      "2024-03-16 07:24:42,063 :: root         : INFO     Time taken:157 seconds\n",
      "2024-03-16 07:24:42,441 :: root         : INFO     Accumulated emb size:torch.Size([26500, 18, 768])\n",
      "2024-03-16 07:27:22,020 :: root         : INFO     Time taken:159 seconds\n",
      "2024-03-16 07:27:22,568 :: root         : INFO     Accumulated emb size:torch.Size([27000, 18, 768])\n",
      "2024-03-16 07:30:00,991 :: root         : INFO     Time taken:158 seconds\n",
      "2024-03-16 07:30:01,370 :: root         : INFO     Accumulated emb size:torch.Size([27500, 18, 768])\n",
      "2024-03-16 07:32:42,328 :: root         : INFO     Time taken:160 seconds\n",
      "2024-03-16 07:32:42,921 :: root         : INFO     Accumulated emb size:torch.Size([28000, 18, 768])\n",
      "2024-03-16 07:35:19,660 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 07:35:20,066 :: root         : INFO     Accumulated emb size:torch.Size([28500, 18, 768])\n",
      "2024-03-16 07:37:56,854 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 07:37:57,323 :: root         : INFO     Accumulated emb size:torch.Size([29000, 18, 768])\n",
      "2024-03-16 07:40:34,115 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 07:40:34,615 :: root         : INFO     Accumulated emb size:torch.Size([29500, 18, 768])\n",
      "2024-03-16 07:43:11,409 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 07:43:11,847 :: root         : INFO     Accumulated emb size:torch.Size([30000, 18, 768])\n",
      "2024-03-16 07:45:48,692 :: root         : INFO     Time taken:156 seconds\n",
      "2024-03-16 07:45:49,474 :: root         : INFO     Accumulated emb size:torch.Size([30500, 18, 768])\n",
      "2024-03-16 07:48:26,569 :: root         : INFO     Time taken:157 seconds\n",
      "2024-03-16 07:48:26,991 :: root         : INFO     Accumulated emb size:torch.Size([31000, 18, 768])\n",
      "2024-03-16 07:51:04,157 :: root         : INFO     Time taken:157 seconds\n",
      "2024-03-16 07:51:04,558 :: root         : INFO     Accumulated emb size:torch.Size([31500, 18, 768])\n",
      "2024-03-16 07:53:49,952 :: root         : INFO     Time taken:165 seconds\n",
      "2024-03-16 07:53:52,462 :: root         : INFO     Accumulated emb size:torch.Size([32000, 18, 768])\n",
      "2024-03-16 07:56:38,562 :: root         : INFO     Time taken:166 seconds\n",
      "2024-03-16 07:56:41,182 :: root         : INFO     Accumulated emb size:torch.Size([32500, 18, 768])\n",
      "2024-03-16 07:59:26,458 :: root         : INFO     Time taken:165 seconds\n",
      "2024-03-16 07:59:28,032 :: root         : INFO     Accumulated emb size:torch.Size([33000, 18, 768])\n",
      "2024-03-16 08:02:12,459 :: root         : INFO     Time taken:164 seconds\n",
      "2024-03-16 08:02:14,249 :: root         : INFO     Accumulated emb size:torch.Size([33500, 18, 768])\n",
      "2024-03-16 08:04:57,493 :: root         : INFO     Time taken:163 seconds\n",
      "2024-03-16 08:04:57,917 :: root         : INFO     Accumulated emb size:torch.Size([34000, 18, 768])\n",
      "2024-03-16 08:07:40,400 :: root         : INFO     Time taken:162 seconds\n",
      "2024-03-16 08:07:40,786 :: root         : INFO     Accumulated emb size:torch.Size([34500, 18, 768])\n",
      "2024-03-16 08:10:23,247 :: root         : INFO     Time taken:162 seconds\n",
      "2024-03-16 08:10:23,673 :: root         : INFO     Accumulated emb size:torch.Size([35000, 18, 768])\n",
      "2024-03-16 08:13:06,131 :: root         : INFO     Time taken:162 seconds\n",
      "2024-03-16 08:13:06,542 :: root         : INFO     Accumulated emb size:torch.Size([35500, 18, 768])\n",
      "2024-03-16 08:15:58,815 :: root         : INFO     Time taken:172 seconds\n",
      "2024-03-16 08:16:00,448 :: root         : INFO     Accumulated emb size:torch.Size([36000, 18, 768])\n",
      "2024-03-16 08:18:47,168 :: root         : INFO     Time taken:166 seconds\n",
      "2024-03-16 08:18:48,852 :: root         : INFO     Accumulated emb size:torch.Size([36500, 18, 768])\n",
      "2024-03-16 08:21:31,449 :: root         : INFO     Time taken:162 seconds\n",
      "2024-03-16 08:21:34,360 :: root         : INFO     Accumulated emb size:torch.Size([37000, 18, 768])\n",
      "2024-03-16 08:24:14,418 :: root         : INFO     Time taken:160 seconds\n",
      "2024-03-16 08:24:16,146 :: root         : INFO     Accumulated emb size:torch.Size([37500, 18, 768])\n",
      "2024-03-16 08:26:54,322 :: root         : INFO     Time taken:158 seconds\n",
      "2024-03-16 08:26:54,980 :: root         : INFO     Accumulated emb size:torch.Size([38000, 18, 768])\n",
      "2024-03-16 08:52:42,930 :: root         : INFO     Time taken:1547 seconds\n",
      "2024-03-16 08:52:48,390 :: root         : INFO     Accumulated emb size:torch.Size([38500, 18, 768])\n",
      "2024-03-16 08:55:27,848 :: root         : INFO     Time taken:159 seconds\n",
      "2024-03-16 08:55:31,316 :: root         : INFO     Accumulated emb size:torch.Size([39000, 18, 768])\n",
      "2024-03-16 08:58:11,295 :: root         : INFO     Time taken:159 seconds\n",
      "2024-03-16 08:58:14,733 :: root         : INFO     Accumulated emb size:torch.Size([39500, 18, 768])\n",
      "2024-03-16 09:00:57,820 :: root         : INFO     Time taken:163 seconds\n",
      "2024-03-16 09:01:00,038 :: root         : INFO     Accumulated emb size:torch.Size([40000, 18, 768])\n",
      "2024-03-16 09:03:38,344 :: root         : INFO     Time taken:158 seconds\n",
      "2024-03-16 09:03:39,710 :: root         : INFO     Accumulated emb size:torch.Size([40500, 18, 768])\n",
      "2024-03-16 09:06:20,185 :: root         : INFO     Time taken:160 seconds\n",
      "2024-03-16 09:06:23,103 :: root         : INFO     Accumulated emb size:torch.Size([41000, 18, 768])\n",
      "2024-03-16 09:09:11,004 :: root         : INFO     Time taken:167 seconds\n",
      "2024-03-16 09:09:15,570 :: root         : INFO     Accumulated emb size:torch.Size([41500, 18, 768])\n",
      "2024-03-16 11:20:55,857 :: root         : INFO     Time taken:7900 seconds\n",
      "2024-03-16 11:21:07,644 :: root         : INFO     Accumulated emb size:torch.Size([42000, 18, 768])\n",
      "2024-03-16 11:23:59,119 :: root         : INFO     Time taken:171 seconds\n",
      "2024-03-16 11:24:08,422 :: root         : INFO     Accumulated emb size:torch.Size([42500, 18, 768])\n",
      "2024-03-16 12:39:33,836 :: root         : INFO     Time taken:4525 seconds\n",
      "2024-03-16 12:39:43,789 :: root         : INFO     Accumulated emb size:torch.Size([43000, 18, 768])\n",
      "2024-03-16 12:42:32,309 :: root         : INFO     Time taken:168 seconds\n",
      "2024-03-16 12:42:39,695 :: root         : INFO     Accumulated emb size:torch.Size([43500, 18, 768])\n",
      "2024-03-16 12:45:30,224 :: root         : INFO     Time taken:170 seconds\n",
      "2024-03-16 12:45:35,173 :: root         : INFO     Accumulated emb size:torch.Size([44000, 18, 768])\n",
      "2024-03-16 12:48:22,050 :: root         : INFO     Time taken:166 seconds\n",
      "2024-03-16 12:48:28,392 :: root         : INFO     Accumulated emb size:torch.Size([44500, 18, 768])\n",
      "2024-03-16 12:51:17,042 :: root         : INFO     Time taken:168 seconds\n",
      "2024-03-16 12:51:21,614 :: root         : INFO     Accumulated emb size:torch.Size([45000, 18, 768])\n",
      "2024-03-16 12:54:11,951 :: root         : INFO     Time taken:170 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 12:54:21,640 :: root         : INFO     Accumulated emb size:torch.Size([45500, 18, 768])\n",
      "2024-03-16 12:56:07,590 :: root         : INFO     Time taken:105 seconds\n",
      "2024-03-16 12:56:12,454 :: root         : INFO     Accumulated emb size:torch.Size([45798, 18, 768])\n",
      "2024-03-16 12:56:12,517 :: root         : INFO     Bert features shape:(45798, 768)\n",
      "2024-03-16 12:56:17,233 :: root         : INFO     Training complete\n",
      "2024-03-16 12:56:17,272 :: root         : INFO     Confusion Matrix:\n",
      "[[ 235  304]\n",
      " [  58 3983]]\n",
      "2024-03-16 12:56:17,305 :: root         : INFO     Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.44      0.56       539\n",
      "           1       0.93      0.99      0.96      4041\n",
      "\n",
      "    accuracy                           0.92      4580\n",
      "   macro avg       0.87      0.71      0.76      4580\n",
      "weighted avg       0.91      0.92      0.91      4580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    classifier=trainer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18393f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "930c6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier_on_new_data(new_df, classifier):\n",
    "    # Load the tokenizer and BERT model\n",
    "    bert = BERT_model()\n",
    "    bert.load_BERT(small=True)\n",
    "\n",
    "    # Tokenize the sentences in the new dataframe\n",
    "    tokenized_df = new_df[0].apply(lambda sent: bert.tokenize_sentence(sent))\n",
    "    MAX_LEN = get_max_sent_length(tokenized_df)\n",
    "\n",
    "    # Convert tokenized sentences to BERT embeddings\n",
    "    bert_hidden_states = bert.convert_tokenized_sent_to_bert_emb(tokenized_df, MAX_LEN)\n",
    "    bert_feature_array = bert_hidden_states[:, 0, :].numpy()\n",
    "\n",
    "    # Predict labels using the trained classifier\n",
    "    predicted_labels = classifier.predict(bert_feature_array)\n",
    "\n",
    "    return predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "630566f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"C:/Users/anany/Desktop/stem.txt\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1f7f05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-23 12:55:39,734 :: root         : INFO     BERT has been loaded successfully\n",
      "2024-03-23 12:55:39,736 :: root         : INFO     Padded array shape:(1, 12)\n",
      "2024-03-23 12:55:39,744 :: root         : INFO     Attention mask shape:(1, 12)\n",
      "2024-03-23 12:55:39,756 :: root         : INFO     Going to get BERT embeddings for 1 records\n",
      "2024-03-23 12:55:39,920 :: root         : INFO     Time taken:0 seconds\n"
     ]
    }
   ],
   "source": [
    "labels=test_classifier_on_new_data(df1,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75808c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1d56f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "678660a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(classifier, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63862664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0d20d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
